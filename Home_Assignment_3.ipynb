{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XUAq3Ugh3gyH",
        "outputId": "984f99fd-758d-423b-be34-3a34f3cf5871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3776 - val_loss: 0.1880\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 0.1788 - val_loss: 0.1537\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1492 - val_loss: 0.1333\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1311 - val_loss: 0.1207\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1197 - val_loss: 0.1128\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.1129 - val_loss: 0.1073\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1075 - val_loss: 0.1033\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1036 - val_loss: 0.1000\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1006 - val_loss: 0.0975\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0982 - val_loss: 0.0957\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0966 - val_loss: 0.0946\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0955 - val_loss: 0.0938\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0948 - val_loss: 0.0933\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0944 - val_loss: 0.0929\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0941 - val_loss: 0.0928\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0940 - val_loss: 0.0925\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0938 - val_loss: 0.0923\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0931 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0932 - val_loss: 0.0917\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0930 - val_loss: 0.0916\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0925 - val_loss: 0.0916\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0922 - val_loss: 0.0914\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0927 - val_loss: 0.0914\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4192 - val_loss: 0.2269\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2124 - val_loss: 0.1806\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1770 - val_loss: 0.1632\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1615 - val_loss: 0.1523\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1515 - val_loss: 0.1454\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1457 - val_loss: 0.1412\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1421 - val_loss: 0.1386\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1391 - val_loss: 0.1363\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1371 - val_loss: 0.1346\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1355 - val_loss: 0.1332\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1342 - val_loss: 0.1319\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.1330 - val_loss: 0.1309\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1320 - val_loss: 0.1302\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1311 - val_loss: 0.1295\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1310 - val_loss: 0.1290\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1308 - val_loss: 0.1287\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1301 - val_loss: 0.1284\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1297 - val_loss: 0.1283\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1300 - val_loss: 0.1279\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1293 - val_loss: 0.1279\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1293 - val_loss: 0.1278\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1294 - val_loss: 0.1276\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1295 - val_loss: 0.1276\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1287 - val_loss: 0.1274\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1290 - val_loss: 0.1274\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1289 - val_loss: 0.1273\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1287 - val_loss: 0.1272\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1287 - val_loss: 0.1271\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1287 - val_loss: 0.1271\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1285 - val_loss: 0.1271\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1288 - val_loss: 0.1270\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1287 - val_loss: 0.1269\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1285 - val_loss: 0.1270\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1281 - val_loss: 0.1269\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1281 - val_loss: 0.1268\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1284 - val_loss: 0.1268\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1284 - val_loss: 0.1267\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1283 - val_loss: 0.1267\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1281 - val_loss: 0.1266\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1280 - val_loss: 0.1266\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1279 - val_loss: 0.1266\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1281 - val_loss: 0.1266\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1282 - val_loss: 0.1265\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1284 - val_loss: 0.1264\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1280 - val_loss: 0.1264\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1282 - val_loss: 0.1264\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1278 - val_loss: 0.1264\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1281 - val_loss: 0.1264\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1278 - val_loss: 0.1263\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1279 - val_loss: 0.1263\n",
            "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
          ]
        }
      ],
      "source": [
        "#q1 : Implementing a Basic Autoencoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images to vectors of size 784 (28x28 pixels)\n",
        "x_train = x_train.reshape((x_train.shape[0], 784))\n",
        "x_test = x_test.reshape((x_test.shape[0], 784))\n",
        "\n",
        "# Step 2: Define the Autoencoder model\n",
        "# Encoder\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(32, activation='relu')(input_img)  # Latent space of size 32\n",
        "\n",
        "# Decoder\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Step 3: Compile the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Step 4: Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Step 5: Visualize original vs. reconstructed images\n",
        "def plot_images(original, reconstructed, num_images=10):\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(num_images):\n",
        "        # Display original images\n",
        "        ax = plt.subplot(2, num_images, i + 1)\n",
        "        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Display reconstructed images\n",
        "        ax = plt.subplot(2, num_images, i + 1 + num_images)\n",
        "        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get reconstructed images\n",
        "reconstructed_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Plot the original vs. reconstructed images\n",
        "plot_images(x_test, reconstructed_imgs)\n",
        "\n",
        "# Step 6: Modify latent dimension size and retrain\n",
        "def experiment_with_latent_dimension(latent_dim):\n",
        "    # Define autoencoder with different latent dimension size\n",
        "    encoded = Dense(latent_dim, activation='relu')(input_img)\n",
        "    decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    # Train the autoencoder\n",
        "    autoencoder.fit(x_train, x_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=256,\n",
        "                    validation_data=(x_test, x_test))\n",
        "\n",
        "    # Get reconstructed images\n",
        "    reconstructed_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "    # Plot original vs reconstructed images\n",
        "    print(f\"Latent Dimension: {latent_dim}\")\n",
        "    plot_images(x_test, reconstructed_imgs)\n",
        "\n",
        "# Experiment with different latent dimensions\n",
        "experiment_with_latent_dimension(16)  # Smaller latent dimension\n",
        "experiment_with_latent_dimension(64)  # Larger latent dimension"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qn 2  : Implementing a Denoising Autoencoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 1. Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# 2. Normalize and reshape the images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "# 3. Add Gaussian noise to the images\n",
        "noise_factor = 0.5\n",
        "noisy_x_train = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "noisy_x_test = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "# Clip the noisy images to make sure the pixel values are in [0, 1]\n",
        "noisy_x_train = np.clip(noisy_x_train, 0.0, 1.0)\n",
        "noisy_x_test = np.clip(noisy_x_test, 0.0, 1.0)\n",
        "\n",
        "# 4. Define the autoencoder architecture\n",
        "input_img = layers.Input(shape=(28, 28, 1))  # Input layer\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)  # First convolution layer\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)  # Max pooling layer\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)  # Second convolution layer\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)  # Max pooling layer (encoded representation)\n",
        "\n",
        "# 5. Decoder part\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)  # Conv layer\n",
        "x = layers.UpSampling2D((2, 2))(x)  # Upsample layer\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Conv layer\n",
        "decoded = layers.UpSampling2D((2, 2))(x)  # Upsample layer\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoded)  # Output layer (reconstruction)\n",
        "\n",
        "# 6. Define the model\n",
        "autoencoder = models.Model(input_img, decoded)\n",
        "\n",
        "# 7. Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# 8. Train the model\n",
        "autoencoder.fit(noisy_x_train, x_train, epochs=50, batch_size=128, validation_data=(noisy_x_test, x_test))\n",
        "\n",
        "# 9. Visualize the results (noisy vs reconstructed)\n",
        "decoded_imgs = autoencoder.predict(noisy_x_test)\n",
        "\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display noisy input images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(noisy_x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(\"Noisy\")\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "WJoCScMI3kew",
        "outputId": "6333d7ab-db39-419d-ecee-1701c3b34527"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m 29/469\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 338ms/step - loss: 0.5185"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2578b1b0bcd8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# 8. Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# 9. Visualize the results (noisy vs reconstructed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qn 3 : Implementing an RNN for Text Generation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load and Preprocess Text Dataset\n",
        "\n",
        "# Define a simple text dataset for this example (you can replace this with a larger dataset)\n",
        "text = \"\"\"\n",
        "    The quick brown fox jumps over the lazy dog.\n",
        "    Pack my box with five dozen liquor jugs.\n",
        "    How razorback-jumping frogs can level six piqued gymnasts!\n",
        "    \"\"\"\n",
        "\n",
        "# Create a set of characters and a mapping from characters to integers and vice versa\n",
        "chars = sorted(set(text))\n",
        "char_to_index = {char: idx for idx, char in enumerate(chars)}\n",
        "index_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "# Convert text to integer sequences\n",
        "text_as_int = np.array([char_to_index[c] for c in text])\n",
        "\n",
        "# Define sequence length (context window) and prepare the data\n",
        "seq_length = 10\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(text_as_int) - seq_length):\n",
        "    X.append(text_as_int[i:i+seq_length])\n",
        "    y.append(text_as_int[i+seq_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Step 2: Define the RNN Model using LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer (Embedding layer)\n",
        "model.add(Embedding(input_dim=len(chars), output_dim=128, input_length=seq_length))\n",
        "\n",
        "# LSTM Layer\n",
        "model.add(LSTM(128))\n",
        "\n",
        "# Output layer (Dense layer)\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.fit(X, y, epochs=50, batch_size=64)\n",
        "\n",
        "# Step 4: Generate Text using the trained model\n",
        "def generate_text(model, start_string, num_generate=100, temperature=1.0):\n",
        "    # Convert start string to integers\n",
        "    input_eval = [char_to_index[s] for s in start_string]\n",
        "    input_eval = np.expand_dims(input_eval, axis=0)  # Make it a batch of size 1\n",
        "\n",
        "    generated_text = start_string\n",
        "\n",
        "    # Generate characters one by one\n",
        "    for i in range(num_generate):\n",
        "        predictions = model.predict(input_eval)\n",
        "\n",
        "        # Use temperature to adjust the randomness of predictions\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = np.argmax(predictions)\n",
        "\n",
        "        # Get the predicted character and append it to the generated text\n",
        "        predicted_char = index_to_char[predicted_id]\n",
        "        generated_text += predicted_char\n",
        "\n",
        "        # Update the input sequence for the next prediction\n",
        "        input_eval = np.roll(input_eval, -1)\n",
        "        input_eval[0, -1] = predicted_id  # Replace the last element with the predicted char index\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Step 5: Generate some text\n",
        "start_string = \"The quick\"\n",
        "generated_text = generate_text(model, start_string, num_generate=100, temperature=0.7)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJxZdAvO6MRz",
        "outputId": "68580935-0415-4b24-f19c-94d4c5147e19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - loss: 3.5253\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.4988\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.4681\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.4156\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.3124\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.1671\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.1432\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.1222\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0855\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0894\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0486\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0593\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.0311\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0190\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.9945\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0087\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0666\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9331\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9918\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0006\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.8986\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.9379\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.8782\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7940\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8416\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.7718\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7881\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7417\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.6579\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.6104\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.5368\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5160\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.4380\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2.3633\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.3382\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2755\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.1602\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2.1815\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.0446\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.0213\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.9310\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.8147\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.7951\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.7351\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.6929\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5846\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5523\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4772\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4015\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3708\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "The quick  o w w iiuurrggnn ss t   eeezzz  bo    azorry n aack  box  iiiiuurgg.  \n",
            "   Hc   ayy     oo zz  aaac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# qn 4  : Sentiment Classification Using RNN\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Load the IMDB sentiment dataset\n",
        "# Load the IMDB dataset with the top 10,000 words\n",
        "max_features = 10000  # Limit the vocabulary to the top 10,000 words\n",
        "maxlen = 200  # Maximum review length (number of words per review)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Step 2: Preprocess the text data\n",
        "# Pad the sequences to ensure they all have the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Step 3: Build the LSTM-based sentiment classifier model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Step 6: Evaluate the model on test data\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Step 7: Generate Confusion Matrix and Classification Report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Step 8: Plot the Confusion Matrix\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Interpret the Precision-Recall Tradeoff\n",
        "# In sentiment analysis, especially when the dataset is imbalanced (e.g., more negative reviews than positive),\n",
        "# we often care more about the recall (sensitivity) of the positive class.\n",
        "# This is because a false negative (predicting a positive review as negative) may have a more significant\n",
        "# impact than a false positive (predicting a negative review as positive).\n",
        "# Precision-Recall tradeoff helps us decide the optimal threshold based on whether we want to prioritize precision\n",
        "# or recall, depending on the task requirements.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "OSR9oDit5mTm",
        "outputId": "1ecd3348-a314-4b21-ae88-d0de1670fe3c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m114/391\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 738ms/step - accuracy: 0.6154 - loss: 0.6419"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-64aabded9bcc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Step 5: Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Step 6: Evaluate the model on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6L_8OdS5uKa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sojvGILw6Dtl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}